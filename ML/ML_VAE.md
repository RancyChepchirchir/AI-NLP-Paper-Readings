# ML - Variational Autoencoders (VAE)
|Paper|Conference|Remarks
|--|--|--|
|[Learning Structured Output Representation using Deep Conditional Generative Models](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)|NIPS 2015|1. Develop a scalable deep conditional generative model for structured output variables using Gaussian latent variables. 2. Provide novel strategies to build a robust structured prediction algorithms, such as recurrent prediction network architecture, input noise-injection and multi-scale prediction training methods.|
|[Tutorial on Variational Autoencoders](https://arxiv.org/pdf/1606.05908)|Arxiv 2016|1. Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions.|
[Back to index](../README.md)
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTYyODQ0NjU1Ml19
-->