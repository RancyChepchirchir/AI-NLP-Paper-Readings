# NLP - Text Generation
|Paper|Conference|Remarks
|--|--|--|
|[Generating Sentences from a Continuous Space](http://www.aclweb.org/anthology/K16-1002)|CoNLL 2016|1. Introduce and study an RNN-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. 2. Present techniques such as KL weight annealing and word drop for solving the difficult learning problem presented by this model.|
|[Toward Controlled Generation of Text](https://arxiv.org/pdf/1703.00955)|ICML 2017|1. Aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. 2. Propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. 3. The proposed model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes.|


[Back to index](../README.md)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE3MjQxMzAzODgsODY3NDczNzIxXX0=
-->