# KR - Knowledge Graph
|Paper|Conference|Remarks
|--|--|--|
|[Representing General Relational Knowledge in ConceptNet 5](http://www.lrec-conf.org/proceedings/lrec2012/pdf/1072_Paper.pdf)|LREC 2012|Presents the latest iteration, ConceptNet 5, including its fundamental design decisions, ways to use it, and evaluations of its coverage and accuracy|
|[Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions](http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/TKDE14-entitylinking.pdf)|TKDE 2014|Entity linking is the task to link entity mentions in text with their corresponding entities in a knowledge base. This survey presents a thorough overview and analysis of the main approaches to entity linking, and discuss various applications, the evaluation of entity linking systems, and future directions.|
|[A Comparative Survey of DBpedia, Freebase, OpenCyc, Wikidata, and YAGO](http://www.semantic-web-journal.net/system/files/swj1141.pdf)|Semantic Web 2015|First defines aspects according to which KGs can be analyzed. Next, this work analyzes and compares the above mentioned KGs along those aspects and finally propose a method for finding the most suitable KG for a given setting.|
|[Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text](https://arxiv.org/pdf/1809.00782)|EMNLP 2018|Approach QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus.|
|[SenticNet 5: Discovering Conceptual Primitives for Sentiment Analysis by Means of Context Embeddings](https://sentic.net/senticnet-5.pdf)|AAAI 2018|1. Couple sub-symbolic and symbolic AI to automatically discover conceptual primitives from text and link them to commonsense concepts and named entities in a new three-level knowledge representation for sentiment analysis. 2. Employ recurrent neural networks to infer primitives by lexical substitution and use them for grounding common and commonsense knowledge by means of multi-dimensional scaling.|
|[Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing](https://arxiv.org/pdf/1802.05930)|NAACL 2018|1. Introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. 2. Shows that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task.|
|[Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing](https://arxiv.org/pdf/1802.05930)|NAACL 2018|1. Introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. 2. Shows that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task.|
|[ConceptNet 5.5: An Open Multilingual Graph of General Knowledge](https://arxiv.org/abs/1612.03975)|AAAI 2018|1. Introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. 2. Shows that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task.|
|[Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing](https://arxiv.org/pdf/1802.05930)|NAACL 2018|1. Introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. 2. Shows that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task.|

[Back to index](../README.md)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE2MTI4Njc1MTMsNTUyNDEyNjYwXX0=
-->